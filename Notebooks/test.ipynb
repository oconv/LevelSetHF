{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting differential operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "torch.set_printoptions(precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx:\n",
      " (tensor([[6., 6.],\n",
      "        [6., 6.]]),)\n",
      "dv/dx:\n",
      " (tensor([[1., 1.],\n",
      "        [1., 1.]]),)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "v = x + 2\n",
    "y = v ** 2\n",
    "\n",
    "dy_dx = grad(outputs=y, inputs=x, grad_outputs=torch.ones_like(y))\n",
    "print(f'dy/dx:\\n {dy_dx}')\n",
    "\n",
    "dv_dx = grad(outputs=v, inputs=x, grad_outputs=torch.ones_like(v))\n",
    "print(f'dv/dx:\\n {dv_dx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFunction(nn.Module):\n",
    "    def __init__(self,input_size=2,output_size=1):\n",
    "        super(MyFunction, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size,5)\n",
    "        self.linear2 = nn.Linear(5,5)\n",
    "        self.linear3 = nn.Linear(5,output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        z = torch.sigmoid(self.linear1(x))\n",
    "        z = torch.sigmoid(self.linear2(z))\n",
    "        z = torch.sigmoid(self.linear3(z))\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dz/dx:\n",
      " tensor([[-0.00243671,  0.00142379],\n",
      "        [-0.00240292,  0.00145341],\n",
      "        [-0.00237762,  0.00152281],\n",
      "        [-0.00236594,  0.00129522],\n",
      "        [-0.00236384,  0.00151623],\n",
      "        [-0.00237377,  0.00149878],\n",
      "        [-0.00241358,  0.00146901],\n",
      "        [-0.00241237,  0.00140220]])\n"
     ]
    }
   ],
   "source": [
    "func = MyFunction()\n",
    "\n",
    "x = torch.rand(8, 2, requires_grad=True)\n",
    "z = func(x)\n",
    "\n",
    "dz_dx = grad(outputs=z, inputs=x, grad_outputs=torch.ones_like(z))[0]\n",
    "print(f'dz/dx:\\n {dz_dx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testm(x):\n",
    "    y = (x + 1) ** 3\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradfn(model, order, xs):\n",
    "    out = model(xs)\n",
    "    for i in range(order):\n",
    "        out = grad(outputs=out, inputs=xs, grad_outputs=torch.ones_like(out), allow_unused=True)[0]\n",
    "        out.requires_grad = True\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using torch.autograd.functional.hessian (for second derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic(x):\n",
    "    y = 3 * x ** 3 + x ** 2 + 4\n",
    "    return torch.sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[38.,  0.],\n",
       "        [ 0., 92.]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([2,5], dtype=torch.float64)\n",
    "\n",
    "torch.autograd.functional.hessian(quadratic, x, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_sec(fn, x, grads):\n",
    "    out = torch.zeros(x.size()[0], len(grads))\n",
    "\n",
    "    for i, xi in enumerate(x):\n",
    "        hess = torch.autograd.functional.hessian(fn, xi, create_graph=True)\n",
    "        for n, dx in enumerate(grads):\n",
    "            out[i,n] = hess[dx]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 20.,  38.],\n",
      "        [ 56.,  74.],\n",
      "        [ 92., 110.],\n",
      "        [128., 146.]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], [3,4], [5, 6], [7, 8]], dtype=torch.float64)\n",
    "\n",
    "print(batch_sec(quadratic, x, grads=[(0,0), (1,1)]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84a5677b4be7885f577fedd0a1d419057b2f10675819fdeb24e51e64e8c778a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
