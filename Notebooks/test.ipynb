{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting differential operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "torch.set_printoptions(precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx:\n",
      " (tensor([[6., 6.],\n",
      "        [6., 6.]]),)\n",
      "dv/dx:\n",
      " (tensor([[1., 1.],\n",
      "        [1., 1.]]),)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "v = x + 2\n",
    "y = v ** 2\n",
    "\n",
    "dy_dx = grad(outputs=y, inputs=x, grad_outputs=torch.ones_like(y))\n",
    "print(f'dy/dx:\\n {dy_dx}')\n",
    "\n",
    "dv_dx = grad(outputs=v, inputs=x, grad_outputs=torch.ones_like(v))\n",
    "print(f'dv/dx:\\n {dv_dx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFunction(nn.Module):\n",
    "    def __init__(self,input_size=2,output_size=1):\n",
    "        super(MyFunction, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size,5)\n",
    "        self.linear2 = nn.Linear(5,5)\n",
    "        self.linear3 = nn.Linear(5,output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        z = torch.sigmoid(self.linear1(x))\n",
    "        z = torch.sigmoid(self.linear2(z))\n",
    "        z = torch.sigmoid(self.linear3(z))\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dz/dx:\n",
      " tensor([[0.00070088, 0.00038788],\n",
      "        [0.00071402, 0.00037485],\n",
      "        [0.00070843, 0.00038154],\n",
      "        [0.00069590, 0.00039529],\n",
      "        [0.00072330, 0.00035239],\n",
      "        [0.00068689, 0.00039576],\n",
      "        [0.00071221, 0.00037727],\n",
      "        [0.00069894, 0.00038993]])\n"
     ]
    }
   ],
   "source": [
    "func = MyFunction()\n",
    "\n",
    "x = torch.rand(8, 2, requires_grad=True)\n",
    "z = func(x)\n",
    "\n",
    "dz_dx = grad(outputs=z, inputs=x, grad_outputs=torch.ones_like(z))[0]\n",
    "print(f'dz/dx:\\n {dz_dx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testm(x):\n",
    "    y = (x + 1) ** 3\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradfn(model, order, xs):\n",
    "    out = model(xs)\n",
    "    for i in range(order):\n",
    "        out = grad(outputs=out, inputs=xs, grad_outputs=torch.ones_like(out), allow_unused=True)[0]\n",
    "        out.requires_grad = True\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using torch.autograd.functional.hessian (for second derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic(x):\n",
    "    y = 3 * x ** 3 + x ** 2 + 4\n",
    "    return torch.sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[38.,  0.],\n",
       "        [ 0., 92.]], dtype=torch.float64, grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([2,5], dtype=torch.float64)\n",
    "\n",
    "torch.autograd.functional.hessian(quadratic, x, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_sec(fn, x, grads): # paralellize this function\n",
    "    out = torch.zeros(x.size()[0], len(grads))\n",
    "\n",
    "    for i, xi in enumerate(x):\n",
    "        hess = torch.autograd.functional.hessian(fn, xi, create_graph=True)\n",
    "        for n, dx in enumerate(grads):\n",
    "            out[i,n] = hess[dx]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2], [3,4], [5, 6], [7, 8]], dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "# print(batch_sec(quadratic, x, grads=[(0,0), (1,1)]))\n",
    "# print(batch_sec(func, x, grads=[(0,0), (1,1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simpler Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_der(y,x):\n",
    "    y_x = grad(y, x, grad_outputs=torch.ones_like(y),\n",
    "    retain_graph=True,\n",
    "    create_graph=True,\n",
    "    allow_unused=True)[0]\n",
    "\n",
    "    y_xx = grad(y_x, x, grad_outputs=torch.ones_like(y_x),\n",
    "    retain_graph=True,\n",
    "    create_graph=True,\n",
    "    allow_unused=True)[0]\n",
    "\n",
    "    return y_xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 20.,  38.],\n",
      "        [ 56.,  74.],\n",
      "        [ 92., 110.],\n",
      "        [128., 146.]], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([[ 6.31085422e-05, -4.60458978e-05],\n",
      "        [-1.19884426e-04, -5.69167169e-05],\n",
      "        [-1.38242845e-04, -4.16072362e-05],\n",
      "        [-8.08083278e-05, -1.79816343e-05]], dtype=torch.float64,\n",
      "       grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "print(sec_der(quadratic(x),x))\n",
    "print(sec_der(func(x.float()),x))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84a5677b4be7885f577fedd0a1d419057b2f10675819fdeb24e51e64e8c778a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
